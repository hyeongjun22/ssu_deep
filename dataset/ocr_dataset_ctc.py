import os
import json
import numpy as np
from PIL import Image
from typing import List, Dict, Tuple
from pydantic import BaseModel, ValidationError

# --- Pydantic ëª¨ë¸ ì •ì˜ (ê¸°ì¡´ê³¼ ë™ì¼) ---
class Annotation(BaseModel):
    object_recognition: int
    text_language: int

class Dataset(BaseModel):
    category: int
    identifier: str
    label_path: str
    name: str
    src_path: str
    type: int

class Images(BaseModel):
    acquistion_location: str
    application_field: str
    background: int
    data_captured: str
    height: int
    identifier: str
    media_type: int
    pen_color: str
    pen_type: int
    type: str
    width: int
    writer_age: int
    writer_sex: int
    written_content: int

class BBox(BaseModel):
    data: str
    id: int
    x: List[int]
    y: List[int]

class Label(BaseModel):
    Annotation: Annotation
    Dataset: Dataset
    Images: Images
    bbox: List[BBox]

# --- CTC í•™ìŠµìš©ìœ¼ë¡œ ìˆ˜ì •ëœ OCR ë°ì´í„°ì…‹ í´ë˜ìŠ¤ ---
class OCRDataset:
    def __init__(self, image_paths_or_dir: any, label_dir: str, vocab_path: str, image_size: Tuple[int, int] = (64, 256), max_label_len: int = 25):
        print("ğŸš€ OCR ë°ì´í„°ì…‹ ì´ˆê¸°í™”ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤...")
        self.image_dir = None
        if isinstance(image_paths_or_dir, str):
            self.image_dir = image_paths_or_dir
            self.image_paths = [os.path.join(self.image_dir, f) for f in os.listdir(self.image_dir) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]
        else:
            self.image_paths = image_paths_or_dir

        self.label_dir = label_dir
        self.image_size = image_size
        self.max_label_len = max_label_len

        # ë‹¨ì–´ì¥ ë¡œë“œ
        with open(vocab_path, 'r', encoding='utf-8') as f:
            self.vocab = json.load(f)
        self.char_to_id = self.vocab['char_to_id']
        self.id_to_char = self.vocab['id_to_char']
        self.vocab_size = len(self.char_to_id)
        self.pad_id = self.char_to_id['<PAD>']
        print(f"âœ… ë‹¨ì–´ì¥ ë¡œë“œ ì™„ë£Œ. ì´ ê¸€ì ìˆ˜: {self.vocab_size}")
        print(f"âœ… ì´ {len(self.image_paths)}ê°œì˜ ì´ë¯¸ì§€ íŒŒì¼ì„ ì²˜ë¦¬ ëŒ€ìƒìœ¼ë¡œ ì„¤ì •í–ˆìŠµë‹ˆë‹¤.")

    def __len__(self):
        return len(self.image_paths)

    def __getitem__(self, idx: int) -> Tuple[List[np.ndarray], List[np.ndarray], List[int]]: # âœ¨ ë°˜í™˜ íƒ€ì…ì— List[int] ì¶”ê°€
        img_path = self.image_paths[idx]
        base_filename = os.path.splitext(os.path.basename(img_path))[0]
        label_path = os.path.join(self.label_dir, f"{base_filename}.json")

        try:
            image = Image.open(img_path).convert('L') # Grayscaleë¡œ ë³€í™˜
            with open(label_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
                label = Label(**data)
        except (FileNotFoundError, ValidationError, json.JSONDecodeError, OSError):
            return [], [], [] # âœ¨ ë°˜í™˜ê°’ ê°œìˆ˜ 3ê°œë¡œ ìˆ˜ì •

        word_images, word_labels, word_label_lengths = [], [], [] # âœ¨ ë¼ë²¨ ê¸¸ì´ ì €ì¥ì„ ìœ„í•œ ë¦¬ìŠ¤íŠ¸ ì¶”ê°€
        for bbox in label.bbox:
            # BBox ì¢Œí‘œë¡œ ì´ë¯¸ì§€ í¬ë¡­ ë° ë¦¬ì‚¬ì´ì¦ˆ
            crop_box = (bbox.x[0], bbox.y[0], bbox.x[2], bbox.y[1])
            word_img = image.crop(crop_box).resize(self.image_size, Image.LANCZOS)
            
            # ì´ë¯¸ì§€ë¥¼ NumPy ë°°ì—´ë¡œ ë³€í™˜í•˜ê³  ì •ê·œí™”
            word_img_np = np.array(word_img, dtype=np.float32) / 255.0
            word_images.append(word_img_np[np.newaxis, :])
            
            # í…ìŠ¤íŠ¸ë¥¼ ID ì‹œí€€ìŠ¤ë¡œ ë³€í™˜
            text = bbox.data
            label_seq = [self.char_to_id.get(char, self.pad_id) for char in text]
            
            # âœ¨ íŒ¨ë”© ì „ ì‹¤ì œ ê¸¸ì´ ì €ì¥
            seq_len = min(len(label_seq), self.max_label_len)
            word_label_lengths.append(seq_len)
            
            # ì‹œí€€ìŠ¤ íŒ¨ë”©
            padded_seq = np.full(self.max_label_len, self.pad_id, dtype=np.int32)
            padded_seq[:seq_len] = label_seq[:seq_len]
            word_labels.append(padded_seq)
            
        return word_images, word_labels, word_label_lengths # âœ¨ 3ê°œ ê°’ ë°˜í™˜

    def get_batch(self, batch_size: int) -> Tuple[np.ndarray, np.ndarray, np.ndarray]: # âœ¨ ë°˜í™˜ íƒ€ì… ìˆ˜ì •
        batch_images, batch_labels, batch_label_lengths = [], [], [] # âœ¨ ë¼ë²¨ ê¸¸ì´ ì €ì¥ì„ ìœ„í•œ ë¦¬ìŠ¤íŠ¸ ì¶”ê°€
        
        while len(batch_images) < batch_size:
            idx = np.random.randint(0, len(self))
            images, labels, lengths = self[idx] # âœ¨ 3ê°œ ê°’ ë°›ê¸°
            
            if images:
                batch_images.extend(images)
                batch_labels.extend(labels)
                batch_label_lengths.extend(lengths) # âœ¨ ë°°ì¹˜ ë¦¬ìŠ¤íŠ¸ì— ê¸¸ì´ ì¶”ê°€

        # ìµœì¢… ë°°ì¹˜ í¬ê¸°ì— ë§ê²Œ ìë¥´ê¸°
        x_batch = np.array(batch_images[:batch_size], dtype=np.float32)
        t_batch = np.array(batch_labels[:batch_size], dtype=np.int32)
        t_len_batch = np.array(batch_label_lengths[:batch_size], dtype=np.int32) # âœ¨ ê¸¸ì´ ë°°ì¹˜ ìƒì„±

        return x_batch, t_batch, t_len_batch # âœ¨ 3ê°œ ê°’ ë°˜í™˜